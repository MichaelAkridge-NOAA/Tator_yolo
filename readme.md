/!\ Under active development. Dataset management + training + calibration workflows evolve quickly; expect periodic changes. /!\

# ü•î Tator ‚Äî Local CLIP + SAM Annotation & Prelabeling Toolkit

Tator is a single‚Äëmachine annotation stack with a browser UI and a FastAPI backend. It focuses on fast, reliable **human labeling** (CLIP + SAM assists) and a deterministic **prepass + calibration** pipeline for high‚Äëquality prelabeling (detectors + SAM3 + XGBoost).

We previously experimented with agentic annotation loops and removed them. Qwen is now used **only** for captioning and for optional glossary expansion used by SAM3 text prompting.

**Vision:** Tator is for teams who already have an object‚Äëdetection dataset (or need to grow one) and want to scale annotation without compromising quality. The goal is to combine strong human‚Äëin‚Äëthe‚Äëloop tools with deterministic automation so you can prelabel quickly, then review and correct with confidence.

---

## What you get

### Fast interactive labeling
- **Auto Class Corrector** ‚Äî CLIP snaps a box to the most likely class.
- **Auto Box Refinement** ‚Äî SAM tightens loose boxes; CLIP verifies the class.
- **Point‚Äëto‚ÄëBox** ‚Äî click once and SAM draws a tight box.
- **Multi‚Äëpoint prompts** ‚Äî add positive/negative points to sculpt tricky objects.

### Deterministic prelabeling (prepass + calibration)
- **Detectors + SAM3** build a high‚Äërecall candidate pool.
- **Dedupe** (IoU merge) stabilizes candidate clusters.
- **Calibration (XGBoost)** filters candidates to maximize F1 while enforcing a recall floor.
- **Glossary management** (dataset glossaries + library) and optional Qwen expansion.

### Training & model management
- **CLIP/DINOv3 head training** from the UI (cached embeddings).
- **YOLOv8 training** and **RF‚ÄëDETR training** with saved‚Äërun management.
- **SAM3 training** from the UI (device selection + run management).
- **Qwen captioning** with windowed mode and guardrails.
- **YOLO head grafting (experimental)** to add new classes without retraining the base backbone.

---

## Repository layout
```
Tator/
‚îú‚îÄ app/                  FastAPI app object (uvicorn imports this)
‚îú‚îÄ localinferenceapi.py  Backend endpoints + orchestration
‚îú‚îÄ ybat-master/          Frontend UI (static HTML/JS/CSS)
‚îú‚îÄ tools/                CLI helpers
‚îú‚îÄ tests/                Unit tests
‚îî‚îÄ uploads/              Runtime artifacts + caches (git-ignored)
```

---

## Prepass + calibration (current default)

### Prepass architecture (detectors + SAM3 + dedupe)
```
Full image
   ‚îÇ
   ‚îú‚îÄ Detectors (YOLO, RF‚ÄëDETR)
   ‚îÇ    ‚îú‚îÄ full‚Äëframe pass
   ‚îÇ    ‚îî‚îÄ SAHI windowed pass (slice + merge)
   ‚îÇ
   ‚îú‚îÄ SAM3 text (glossary terms + optional Qwen expansion)
   ‚îÇ
   ‚îú‚îÄ Dedupe A (IoU merge) + optional cleanup
   ‚îÇ    ‚îî‚îÄ classifier cleanup only if prepass_keep_all=false
   ‚îÇ
   ‚îú‚îÄ SAM3 similarity (global full‚Äëframe)
   ‚îÇ    ‚îî‚îÄ optional windowed similarity extension
   ‚îÇ
   ‚îî‚îÄ Dedupe B (IoU merge) + optional cleanup
        ‚îî‚îÄ final prepass candidate set (with provenance)
```

Key notes:
- **Full‚Äëframe + SAHI**: every detector runs twice (full‚Äëframe + SAHI) then merges.
- **SAM3 text**: driven by the dataset glossary (optionally expanded by Qwen).
- **Similarity**: global similarity is always on; windowed similarity is optional.
- **Dedupe**: run twice (after detectors + text; after similarity).
- **Calibration**: uses `prepass_keep_all=true` (no classifier gating) so the model sees the full candidate pool.

### Calibration workflow + caching
- Jobs stored under `uploads/calibration_jobs/<job_id>/`.
- Intermediate prepass/features/labels cached under `uploads/calibration_cache/` keyed by payload hash.
- Poll status via `GET /calibration/jobs/{job_id}`.

### Calibration benchmark (IoU=0.50, qwen_dataset, validation split)
| Dataset size | Windowed SAM3 text | Windowed SAM3 similarity | Pipeline | Precision | Recall | F1 |
| --- | --- | --- | --- | --- | --- | --- |
| 4000 | no | no | YOLO‚Äësupported clusters (source_list contains yolo) | 0.769 | 0.532 | 0.629 |
| 4000 | no | no | RF‚ÄëDETR‚Äësupported clusters (source_list contains rfdetr) | 0.712 | 0.562 | 0.628 |
| 4000 | no | no | YOLO + RF‚ÄëDETR (dedupe on source_list union) | 0.663 | 0.635 | 0.649 |
| 4000 | no | no | **Prepass + XGBoost (context)** | **0.850** | **0.799** | **0.824** |
| 2000 | no | no | **Prepass + XGBoost (context)** | **0.844** | **0.688** | **0.758** |
| 2000 | yes (2√ó2) | yes (2√ó2) | **Prepass + XGBoost (context)** | **0.737** | **0.485** | **0.585** |

Notes:
- Detector baselines above are derived from **prepass clusters** using `source_list` membership (more faithful than `score_source` alone).
- IoU=0.50 is used for calibration selection (recall‚Äëfriendly for prelabeling). For stricter downstream evaluation, use IoU=0.75 or higher.
- **Windowed cost**: enabling 2√ó2 windowed SAM3 text+similarity increased throughput from ~20 s/img to ~31 s/img (‚âà+55%) on dual A6000s in our qwen_dataset runs. Expect variation by GPU/model.

---

## Feature highlights (current status)
- **Labeling assists**: auto‚Äëclass, SAM refinement, multi‚Äëpoint prompts.
- **SAM variants**: SAM1/SAM2 for interactive use; SAM3 for text prompting + similarity.
- **Prepass + calibration**: deterministic prepass + XGBoost filtering (default).
- **Glossary library**: dataset glossaries + named glossary library + optional Qwen expansion.
- **Captioning**: Qwen captioning with windowed 2√ó2 tiles and detail‚Äëpreserving merge.
- **Training**: CLIP/DINOv3 heads, YOLOv8, RF‚ÄëDETR, SAM3.
- **Experimental**: YOLO head grafting (add new classes onto an existing YOLO run).
- **Run management**: download/delete/rename for trained classifiers and detectors.

---

## Third‚Äëparty tools & licenses (read before use)

Tator integrates several upstream tools. You are responsible for reviewing and complying with their licenses:

- **Ultralytics YOLOv8** ‚Äî AGPL‚Äë3.0
  - https://github.com/ultralytics/ultralytics/blob/main/LICENSE
  - https://www.ultralytics.com/license
- **RF‚ÄëDETR** ‚Äî Apache‚Äë2.0
  - https://github.com/roboflow/rf-detr/blob/main/LICENSE
- **Meta SAM / SAM3** ‚Äî check Meta‚Äôs licenses before use
  - https://github.com/facebookresearch/segment-anything
  - https://github.com/facebookresearch/sam3 (and the Hugging Face model cards)
- **Qwen3** ‚Äî review Qwen model license
  - https://huggingface.co/Qwen
- **XGBoost** ‚Äî Apache‚Äë2.0
  - https://github.com/dmlc/xgboost/blob/master/LICENSE

---

## Installation

### Prerequisites
- Python 3.10+ (3.11 recommended).
- Optional NVIDIA GPU with CUDA for faster CLIP/SAM/Qwen.
- Model weights (SAM1 required, SAM3 optional).
- If you use YOLO training/head‚Äëgrafting, you must comply with the Ultralytics license/TOS.

### Quick start
1. **Create env**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```
2. **Install deps**
   ```bash
   pip install -r requirements.txt
   ```
   Torch wheels are hardware‚Äëspecific; install the build matching your CUDA stack if needed.
3. **Install dev tools (optional)**
   ```bash
   pip install -r requirements-dev.txt
   pre-commit install
   ```
4. **Model weights**
   - Place `sam_vit_h_4b8939.pth` in the repo root (SAM1).
   - Optional SAM3 setup: see below.
5. **Configure**
   ```bash
   cp .env.example .env
   ```
   Update `.env` as needed:
   ```bash
   LOGREG_PATH=./my_logreg_model.pkl
   LABELMAP_PATH=./my_label_list.pkl
   CLIP_MODEL_NAME=ViT-B/32
   SAM_VARIANT=sam1
   SAM_CHECKPOINT_PATH=./sam_vit_h_4b8939.pth
   SAM3_MODEL_ID=facebook/sam3
   SAM3_PROCESSOR_ID=facebook/sam3
   SAM3_CHECKPOINT_PATH=
   SAM3_DEVICE=
   QWEN_MODEL_NAME=Qwen/Qwen3-VL-4B-Instruct
   QWEN_DEVICE=auto
   QWEN_MAX_NEW_TOKENS=768
   ```
6. **Run API**
   ```bash
   python -m uvicorn app:app --host 0.0.0.0 --port 8000
   ```
7. **Open UI**
   - open `ybat-master/ybat.html` in a browser.

---

## Dataset management & glossaries
- Upload datasets in **Datasets** tab (YOLO preferred). COCO is auto‚Äëconverted to YOLO to preserve label order.
- Uploading the current labeling session can optionally create a **train/val split** (seeded shuffle).
- Each dataset has a **canonical glossary** for SAM3 text prompts.
- A **glossary library** (named glossaries) is available for reuse across datasets.
- Optional **dataset context** is stored with the dataset and used in Qwen captioning/term expansion prompts.

---

## Captioning (Qwen)
- **Windowed mode** is always 2√ó2 tiles with ~20% overlap; tiles are scaled to model input size.
- The merge prompt is tuned to preserve detail across windows (people counts, vehicles, unique objects).
- Labelmap tokens are explicitly discouraged in final captions; natural language is preferred.

---

## Experimental: YOLOv8 head grafting
Head grafting lets you train a new detection head for <em>new classes</em> and merge it into an existing YOLOv8
run without retraining the backbone. This is useful when you want to expand a labelmap incrementally.

**Requirements**
- Base run must be **YOLO detect** (not segmentation) and already trained.
- New dataset must be **YOLO‚Äëready** and contain **only new classes**.
- Base and new labelmaps must be **disjoint** (no overlapping class names).
- Works with standard YOLOv8 and YOLOv8‚ÄëP2 variants.

**How it works**
1. Create a YOLOv8 head model for the new dataset (`nc = new classes`).
2. Load base weights, freeze backbone, and train only the new head.
3. Build a merged model with two Detect heads + a ConcatHead.
4. Append the new labelmap to the base labelmap (base classes remain intact).

**Outputs**
- `best.pt` with merged weights.
- `labelmap.txt` with base classes followed by new classes.
- Optional ONNX export.
- `head_graft_audit.jsonl` with a per‚Äëstep audit trail.
- ‚ÄúHead‚Äëgraft bundle‚Äù download includes `best.pt`, `labelmap.txt`, merged YAML, audit log, and `run.json`.

**Notes**
- This flow patches Ultralytics at runtime to add `ConcatHead`. Treat as experimental.
- The merged model‚Äôs class order is deterministic: base classes first, new classes last.
- Launch from the **Train YOLO** tab ‚Üí **YOLO Head Grafting (experimental)** panel.
 - Inference automatically loads the runtime patch when a grafted YOLO run is activated.


## Optional: SAM3 setup
SAM3 support is optional but recommended for text prompting + similarity.

1. **Request checkpoint access** on Hugging Face.
2. **Install SAM3 repo**
   ```bash
   git clone https://github.com/facebookresearch/sam3.git
   cd sam3
   pip install -e .
   pip install einops
   ```
3. **Authenticate**
   ```bash
   hf auth login
   ```
4. **Run API** ‚Äî select SAM3 in the UI.

---

## Updates (major changes)
- **2026‚Äë01‚Äë23**: Removed agentic annotation loop; standardized deterministic prepass + calibration.
- **2026‚Äë01‚Äë27**: Calibration caching + XGBoost context features stabilized.
- **2026‚Äë01‚Äë29**: 4000‚Äëimage calibration evaluation (IoU=0.50) and glossary library updates.
- **2026‚Äë01‚Äë29**: SAM3 text prepass reworked to reuse cached image state across prompts (tile‚Äëfirst).

---

## Prepass smoke test (CLI)
```bash
bash tools/run_qwen_prepass_smoke.sh --count 10 --seed 42 --dataset qwen_dataset
```

## Prepass benchmark (CLI)
```bash
bash tools/run_qwen_prepass_benchmark.sh --count 10 --seed 42 --dataset qwen_dataset
```

---

## Codebase map (where to look)
```
Tator/
‚îú‚îÄ app/                  FastAPI app object
‚îú‚îÄ localinferenceapi.py  Backend endpoints + orchestration
‚îú‚îÄ ybat-master/          Frontend UI (HTML/JS/CSS)
‚îú‚îÄ tools/                CLI helpers
‚îú‚îÄ tests/                Unit tests
‚îî‚îÄ uploads/              Runtime artifacts + caches
```
